{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5783962-8614-44b0-842e-dfa54e90e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from skmultilearn.adapt import MLkNN\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb3563d-f693-4c88-9519-864799fdc324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ta_a1</th>\n",
       "      <th>ta_a2</th>\n",
       "      <th>ta_a3</th>\n",
       "      <th>ta_a4</th>\n",
       "      <th>ta_a5</th>\n",
       "      <th>ta_a6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*1. роорпБро░роЪрпКро▓ро┐ роЕро▓рпБро╡ро▓роХроорпН роЕроорпИроирпНродрпБро│рпНро│ роЗроЯроорпН рокроЮрпНроЪрооро┐...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>роЪрпЛродрпНродрпБроХрпНроХрпБ рокро┐роЪрпНроЪрпИ роОроЯрпБроХрпНроХро┐ро▒ роХроЯроЩрпНроХро╛ро░ роиро╛ропрпНроХро│рпБроХ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>родродрпНродрокрпБродрпНрод родродрпНродрокрпБродрпНрод ройрпНройрпБ роОродро╛ро╡родрпБ рокрпБро░ро┐ропрпБродро╛</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>рокроЪрпНроЪрпИ роорпКро│роХро╛ роХро╛ро░роорпН vicky роЕроорпНрооро╛ рокрпБрогрпНроЯрпИ роиро╛ро▒рпБроорпН ЁЯШЖ</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>роОройрпНрой роЙроЯроорпНрокрпБ роЯро╛ роЪро╛рооро┐- роЪрпБроорпНрооро╛ ро╡ро│рпБро╡ро│рпБройрпБ.. роорпБро▓рпИ ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6774</th>\n",
       "      <td>ЁЯШнЁЯШнЁЯШн роТроорпНрооро╛ро│ рокроЯро┐роХрпНроХро▓рпН рокрпБрогрпНроЯ ЁЯШнЁЯШнЁЯШн</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>ЁЯЩДЁЯЩДЁЯЩДЁЯЩД роОройрпНрой роОро┤ро╡рпБропро╛ роЗродрпБ...   роЗродрпЖро▓рпНро▓ро╛роорпН роТро░рпБ рокрпЖро░рпБроорпИ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>ЁЯЪироОроХрпНро╕рпН рокро┐ро░ро╕рпН рокрпЗро░рпНро▓рпН роХрокрпНрокро▓рпН родрпА ро╡ро┐рокродрпНродрпБроХрпНроХрпБ роЙро│рпНро│...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>ЁЯдг ЁЯдг роЪро▓рпНро▓ро┐ роЬро╛родро┐ ро╡рпЖро▒ро┐ роорпБроЯрпНроЯро╛ рокрпБрогрпНроЯ роЙроЩрпНроХ рокрпКрогрпНрогрпБроЩрпН...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>ЁЯдгЁЯдгЁЯдг роирпА роЪрпКро▓рпНро▒родрпБ роОро▓рпНро▓ро╛роорпБроорпН роЕроирпНрод родро┐роорпНроХро╡рпЛроЯ родроорпНрокро┐  ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6779 rows ├Ч 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   unique_id  ta_a1  \\\n",
       "0        *1. роорпБро░роЪрпКро▓ро┐ роЕро▓рпБро╡ро▓роХроорпН роЕроорпИроирпНродрпБро│рпНро│ роЗроЯроорпН рокроЮрпНроЪрооро┐...  question_1    NaN   \n",
       "1        роЪрпЛродрпНродрпБроХрпНроХрпБ рокро┐роЪрпНроЪрпИ роОроЯрпБроХрпНроХро┐ро▒ роХроЯроЩрпНроХро╛ро░ роиро╛ропрпНроХро│рпБроХ...  question_1    NaN   \n",
       "2              родродрпНродрокрпБродрпНрод родродрпНродрокрпБродрпНрод ройрпНройрпБ роОродро╛ро╡родрпБ рокрпБро░ро┐ропрпБродро╛  question_1    NaN   \n",
       "3         рокроЪрпНроЪрпИ роорпКро│роХро╛ роХро╛ро░роорпН vicky роЕроорпНрооро╛ рокрпБрогрпНроЯрпИ роиро╛ро▒рпБроорпН ЁЯШЖ  question_1    NaN   \n",
       "4       роОройрпНрой роЙроЯроорпНрокрпБ роЯро╛ роЪро╛рооро┐- роЪрпБроорпНрооро╛ ро╡ро│рпБро╡ро│рпБройрпБ.. роорпБро▓рпИ ...  question_1    1.0   \n",
       "...                                                 ...         ...    ...   \n",
       "6774                      ЁЯШнЁЯШнЁЯШн роТроорпНрооро╛ро│ рокроЯро┐роХрпНроХро▓рпН рокрпБрогрпНроЯ ЁЯШнЁЯШнЁЯШн  question_1    NaN   \n",
       "6775  ЁЯЩДЁЯЩДЁЯЩДЁЯЩД роОройрпНрой роОро┤ро╡рпБропро╛ роЗродрпБ...   роЗродрпЖро▓рпНро▓ро╛роорпН роТро░рпБ рокрпЖро░рпБроорпИ...  question_1    NaN   \n",
       "6776  ЁЯЪироОроХрпНро╕рпН рокро┐ро░ро╕рпН рокрпЗро░рпНро▓рпН роХрокрпНрокро▓рпН родрпА ро╡ро┐рокродрпНродрпБроХрпНроХрпБ роЙро│рпНро│...  question_1    NaN   \n",
       "6777  ЁЯдг ЁЯдг роЪро▓рпНро▓ро┐ роЬро╛родро┐ ро╡рпЖро▒ро┐ роорпБроЯрпНроЯро╛ рокрпБрогрпНроЯ роЙроЩрпНроХ рокрпКрогрпНрогрпБроЩрпН...  question_1    NaN   \n",
       "6778  ЁЯдгЁЯдгЁЯдг роирпА роЪрпКро▓рпНро▒родрпБ роОро▓рпНро▓ро╛роорпБроорпН роЕроирпНрод родро┐роорпНроХро╡рпЛроЯ родроорпНрокро┐  ...  question_1    NaN   \n",
       "\n",
       "      ta_a2  ta_a3  ta_a4  ta_a5  ta_a6  label  \n",
       "0       NaN    0.0    0.0    0.0    0.0      0  \n",
       "1       NaN    NaN    0.0    NaN    NaN      0  \n",
       "2       NaN    NaN    NaN    0.0    NaN      0  \n",
       "3       NaN    NaN    NaN    1.0    NaN      1  \n",
       "4       NaN    NaN    NaN    NaN    NaN      1  \n",
       "...     ...    ...    ...    ...    ...    ...  \n",
       "6774    NaN    1.0    NaN    NaN    NaN      1  \n",
       "6775    NaN    NaN    NaN    0.0    NaN      0  \n",
       "6776    0.0    NaN    NaN    NaN    NaN      0  \n",
       "6777    0.0    NaN    NaN    NaN    NaN      0  \n",
       "6778    NaN    1.0    NaN    NaN    NaN      1  \n",
       "\n",
       "[6779 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2= pd.read_csv('train_ta_l1.csv')\n",
    "d2\n",
    "d2 = d2.rename(columns={'key' : 'unique_id', 'sentence' : 'text'})\n",
    "d2.to_csv('updated_train_ta_l1.csv', index=False)\n",
    "# d2\n",
    "\n",
    "# Convert annotator columns to numeric without replacing NaNs\n",
    "d2[['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']] = d2[\n",
    "    ['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']\n",
    "].apply(pd.to_numeric, errors='coerce')  # NaNs are retained\n",
    "\n",
    "# Compute 'label' based on majority voting while ignoring NaNs\n",
    "d2['label'] = (\n",
    "    d2[['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']].mean(axis=1, skipna=True) >= 0.5\n",
    ").astype(int)\n",
    "\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af2e821-1964-4cf9-94c4-df0826f9953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary label ('hate' or 'not_hate')\n",
    "def determine_binary_label(label):\n",
    "    return 'hate' if label == 1 else 'not_hate'\n",
    "\n",
    "d2['binary_label'] = d2['label'].apply(determine_binary_label)\n",
    "\n",
    "# # Reorder columns\n",
    "d2 = d2[['unique_id', 'text', 'binary_label', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de3832b-132b-48d5-85d7-f0eade4e43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.to_csv('updated_train_ta_l1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae33934-d68d-4281-a5f4-cde28ac136e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>роорпБро░роЪрпКро▓ро┐ роЕро▓рпБро╡ро▓роХроорпН роЕроорпИроирпНродрпБро│рпНро│ роЗроЯроорпН рокроЮрпНроЪрооро┐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>роЪрпЛродрпНродрпБроХрпНроХрпБ рокро┐роЪрпНроЪрпИ роОроЯрпБроХрпНроХро┐ро▒ роХроЯроЩрпНроХро╛ро░ роиро╛ропрпНроХро│рпБроХ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>родродрпНродрокрпБродрпНрод родродрпНродрокрпБродрпНрод ройрпНройрпБ роОродро╛ро╡родрпБ рокрпБро░ро┐ропрпБродро╛</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>рокроЪрпНроЪрпИ роорпКро│роХро╛ роХро╛ро░роорпН vicky роЕроорпНрооро╛ рокрпБрогрпНроЯрпИ роиро╛ро▒рпБроорпН</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>роОройрпНрой роЙроЯроорпНрокрпБ роЯро╛ роЪро╛рооро┐  роЪрпБроорпНрооро╛ ро╡ро│рпБро╡ро│рпБройрпБ   роорпБро▓рпИ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0         роорпБро░роЪрпКро▓ро┐ роЕро▓рпБро╡ро▓роХроорпН роЕроорпИроирпНродрпБро│рпНро│ роЗроЯроорпН рокроЮрпНроЪрооро┐...\n",
       "1     роЪрпЛродрпНродрпБроХрпНроХрпБ рокро┐роЪрпНроЪрпИ роОроЯрпБроХрпНроХро┐ро▒ роХроЯроЩрпНроХро╛ро░ роиро╛ропрпНроХро│рпБроХ...\n",
       "2           родродрпНродрокрпБродрпНрод родродрпНродрокрпБродрпНрод ройрпНройрпБ роОродро╛ро╡родрпБ рокрпБро░ро┐ропрпБродро╛\n",
       "3       рокроЪрпНроЪрпИ роорпКро│роХро╛ роХро╛ро░роорпН vicky роЕроорпНрооро╛ рокрпБрогрпНроЯрпИ роиро╛ро▒рпБроорпН \n",
       "4    роОройрпНрой роЙроЯроорпНрокрпБ роЯро╛ роЪро╛рооро┐  роЪрпБроорпНрооро╛ ро╡ро│рпБро╡ро│рпБройрпБ   роорпБро▓рпИ ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"\n",
    "                               u\"\\U0001F700-\\U0001F77F\"\n",
    "                               u\"\\U0001F780-\\U0001F7FF\"\n",
    "                               u\"\\U0001F800-\\U0001F8FF\"\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"\n",
    "                               u\"\\U0001FA00-\\U0001FA6F\"\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', ' ', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'<.*?>+', ' ', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', ' ', text)\n",
    "    text = re.sub(r'<handle replaced>', '', text)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    return text\n",
    "\n",
    "## Apply the written function ##\n",
    "d2.loc[:, 'text'] = d2['text'].apply(lambda x: normalize_text(x))\n",
    "processed_list = []\n",
    "for j in d2['text']:\n",
    "    process = j.replace('...','')\n",
    "    processed_list.append(process)\n",
    "\n",
    "df_processed = pd.DataFrame(processed_list)\n",
    "df_processed.columns = ['text']\n",
    "df_processed.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27af7a3-167d-4465-b075-974bfc49c97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], shape=(6779, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(df_processed['text'])\n",
    "y = d2[['label']].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e906650-ffa5-4785-bef1-0c09e638b0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1557 2466  444 ...    0    0    0]\n",
      " [1396  323 2468 ...    0    0    0]\n",
      " [ 135  520 2470 ...    0    0    0]\n",
      " ...\n",
      " [3879 2142 1100 ...    0    0    0]\n",
      " [ 406  430  602 ...    0    0    0]\n",
      " [   4  850   13 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Activation, Dropout, Dense, Flatten,\n",
    "    Bidirectional, GRU, concatenate, SpatialDropout1D,\n",
    "    GlobalMaxPooling1D, GlobalAveragePooling1D, Conv1D,\n",
    "    Embedding, Input, Concatenate\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "######## Textual Features for Embedding ###################\n",
    "max_len = 100\n",
    "max_features = 4479\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "\n",
    "print(X)  # Check the processed sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae2a9fe1-8da2-41f4-a7d8-6270ad4924ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], shape=(6779,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y.ravel())\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44cf827-b666-43aa-bb90-a0bfaaf06e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], shape=(6779, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f690ac8d-e7f8-4d08-a6a0-d34b764c6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.loc[:, 'binary_label'] = d2['label'].apply(determine_binary_label)\n",
    "\n",
    "# # Reorder columns\n",
    "d2 = d2[['unique_id', 'text', 'binary_label', 'label']]\n",
    "\n",
    "d2.to_csv('updated_test_en_l1.csv', index=False)\n",
    "\n",
    "d2.loc[:, 'text'] = d2['text'].apply(lambda x: normalize_text(x))\n",
    "processed_list = []\n",
    "for j in d2['text']:\n",
    "    process = j.replace('...','')\n",
    "    processed_list.append(process)\n",
    "\n",
    "df_processed = pd.DataFrame(processed_list)\n",
    "df_processed.columns = ['text']\n",
    "df_processed.head(n=5)\n",
    "\n",
    "X = list(df_processed['text'])\n",
    "y = d2[['label']].values\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "\n",
    "y = label_encoder.fit_transform(y.ravel())\n",
    "\n",
    "y = to_categorical(y, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45303829-6c10-4e1a-b901-2c86ec814b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (4479, 50)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load GloVe embeddings from JSON\n",
    "with open('glove_embeddings.json', encoding=\"utf8\") as f:\n",
    "    embeddings_list = json.load(f)\n",
    "\n",
    "# Convert the list of vectors to a dictionary with word indices as keys\n",
    "embeddings_dictionary = {str(i): vector for i, vector in enumerate(embeddings_list)}\n",
    "\n",
    "# Define tokenizer \n",
    "vocab_size = len(tokenizer.word_index) + 1  # Vocabulary size\n",
    "word_index = tokenizer.word_index\n",
    "num_words = min(max_features, vocab_size)  # Limit vocab to max_features\n",
    "\n",
    "# Get embedding dimension (from first vector in list)\n",
    "embed_size = len(embeddings_list[0]) if embeddings_list else 0\n",
    "\n",
    "# Initialize embedding matrix\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "\n",
    "# Fill embedding matrix with corresponding word vectors\n",
    "for word, index in word_index.items():\n",
    "    if index >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dictionary.get(word) or embeddings_dictionary.get(str(index))\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = np.asarray(embedding_vector, dtype=np.float32)\n",
    "\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b96bc87-e323-4e7d-9937-8d77c29f8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5423\n",
      "Validation samples: 1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krmri\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">тФПтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФУ\n",
       "тФГ<span style=\"font-weight: bold\"> Layer (type)                  </span>тФГ<span style=\"font-weight: bold\"> Output Shape              </span>тФГ<span style=\"font-weight: bold\">         Param # </span>тФГ<span style=\"font-weight: bold\"> Connected to               </span>тФГ\n",
       "тФбтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФй\n",
       "тФВ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ -                          тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)           тФВ         <span style=\"color: #00af00; text-decoration-color: #00af00\">223,950</span> тФВ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ spatial_dropout1d             тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)           тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          тФВ         <span style=\"color: #00af00; text-decoration-color: #00af00\">138,240</span> тФВ spatial_dropout1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ bidirectional_1               тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          тФВ         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> тФВ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ multi_head_attention          тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          тФВ          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> тФВ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          тФВ                           тФВ                 тФВ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     тФВ\n",
       "тФВ                               тФВ                           тФВ                 тФВ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ global_average_pooling1d      тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ global_max_pooling1d          тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">тАж</span> тФВ\n",
       "тФВ                               тФВ                           тФВ                 тФВ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               тФВ         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> тФВ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ batch_normalization           тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               тФВ           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> тФВ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               тФВ          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> тФВ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ batch_normalization_1         тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               тФВ             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> тФВ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              тФВ\n",
       "тФВ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               тФВ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> тФВ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">тАж</span> тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               тФВ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 тФВ             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> тФВ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            тФВ\n",
       "тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ\n",
       "</pre>\n"
      ],
      "text/plain": [
       "тФПтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФ│тФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФУ\n",
       "тФГ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mтФГ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mтФГ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mтФГ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mтФГ\n",
       "тФбтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтХЗтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФй\n",
       "тФВ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ -                          тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)           тФВ         \u001b[38;5;34m223,950\u001b[0m тФВ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ spatial_dropout1d             тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m50\u001b[0m)           тФВ               \u001b[38;5;34m0\u001b[0m тФВ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            тФВ\n",
       "тФВ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          тФВ         \u001b[38;5;34m138,240\u001b[0m тФВ spatial_dropout1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ bidirectional_1               тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          тФВ         \u001b[38;5;34m123,648\u001b[0m тФВ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        тФВ\n",
       "тФВ (\u001b[38;5;33mBidirectional\u001b[0m)               тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ multi_head_attention          тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          тФВ          \u001b[38;5;34m66,048\u001b[0m тФВ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     тФВ\n",
       "тФВ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          тФВ                           тФВ                 тФВ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          тФВ               \u001b[38;5;34m0\u001b[0m тФВ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     тФВ\n",
       "тФВ                               тФВ                           тФВ                 тФВ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ global_average_pooling1d      тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          тФВ\n",
       "тФВ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ global_max_pooling1d          тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          тФВ\n",
       "тФВ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ global_average_pooling1d[\u001b[38;5;34mтАж\u001b[0m тФВ\n",
       "тФВ                               тФВ                           тФВ                 тФВ global_max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense (\u001b[38;5;33mDense\u001b[0m)                 тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               тФВ         \u001b[38;5;34m131,328\u001b[0m тФВ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ batch_normalization           тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               тФВ           \u001b[38;5;34m1,024\u001b[0m тФВ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                тФВ\n",
       "тФВ (\u001b[38;5;33mBatchNormalization\u001b[0m)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense_1 (\u001b[38;5;33mDense\u001b[0m)               тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               тФВ          \u001b[38;5;34m32,896\u001b[0m тФВ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ batch_normalization_1         тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               тФВ             \u001b[38;5;34m512\u001b[0m тФВ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              тФВ\n",
       "тФВ (\u001b[38;5;33mBatchNormalization\u001b[0m)          тФВ                           тФВ                 тФВ                            тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               тФВ               \u001b[38;5;34m0\u001b[0m тФВ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mтАж\u001b[0m тФВ\n",
       "тФЬтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ╝тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФд\n",
       "тФВ dense_2 (\u001b[38;5;33mDense\u001b[0m)               тФВ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 тФВ             \u001b[38;5;34m258\u001b[0m тФВ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            тФВ\n",
       "тФФтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФ┤тФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФАтФШ\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">717,904</span> (2.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m717,904\u001b[0m (2.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">717,136</span> (2.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m717,136\u001b[0m (2.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.5000 - loss: 1.0184 - macro_f1_score: 0.5000 \n",
      "Epoch 1: macro_f1_score improved from -inf to 0.50876, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 218ms/step - accuracy: 0.5000 - loss: 1.0178 - macro_f1_score: 0.5000 - val_accuracy: 0.5737 - val_loss: 0.6857 - val_macro_f1_score: 0.5737\n",
      "Epoch 2/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5328 - loss: 0.7713 - macro_f1_score: 0.5328 \n",
      "Epoch 2: macro_f1_score improved from 0.50876 to 0.52886, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 215ms/step - accuracy: 0.5327 - loss: 0.7713 - macro_f1_score: 0.5327 - val_accuracy: 0.5494 - val_loss: 0.6924 - val_macro_f1_score: 0.5494\n",
      "Epoch 3/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.5449 - loss: 0.7333 - macro_f1_score: 0.5449 \n",
      "Epoch 3: macro_f1_score improved from 0.52886 to 0.54988, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 225ms/step - accuracy: 0.5449 - loss: 0.7333 - macro_f1_score: 0.5449 - val_accuracy: 0.5878 - val_loss: 0.6656 - val_macro_f1_score: 0.5878\n",
      "Epoch 4/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6206 - loss: 0.6566 - macro_f1_score: 0.6206 \n",
      "Epoch 4: macro_f1_score improved from 0.54988 to 0.64909, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 232ms/step - accuracy: 0.6208 - loss: 0.6564 - macro_f1_score: 0.6208 - val_accuracy: 0.7271 - val_loss: 0.5578 - val_macro_f1_score: 0.7271\n",
      "Epoch 5/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.7419 - loss: 0.5255 - macro_f1_score: 0.7419 \n",
      "Epoch 5: macro_f1_score improved from 0.64909 to 0.74940, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 232ms/step - accuracy: 0.7419 - loss: 0.5254 - macro_f1_score: 0.7419 - val_accuracy: 0.7478 - val_loss: 0.5034 - val_macro_f1_score: 0.7478\n",
      "Epoch 6/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.7779 - loss: 0.4731 - macro_f1_score: 0.7779 \n",
      "Epoch 6: macro_f1_score improved from 0.74940 to 0.78517, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 221ms/step - accuracy: 0.7779 - loss: 0.4731 - macro_f1_score: 0.7779 - val_accuracy: 0.7242 - val_loss: 0.6280 - val_macro_f1_score: 0.7242\n",
      "Epoch 7/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.8079 - loss: 0.4257 - macro_f1_score: 0.8079 \n",
      "Epoch 7: macro_f1_score improved from 0.78517 to 0.81910, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 225ms/step - accuracy: 0.8080 - loss: 0.4256 - macro_f1_score: 0.8080 - val_accuracy: 0.7721 - val_loss: 0.5069 - val_macro_f1_score: 0.7721\n",
      "Epoch 8/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.8330 - loss: 0.3856 - macro_f1_score: 0.8330 \n",
      "Epoch 8: macro_f1_score improved from 0.81910 to 0.83054, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 230ms/step - accuracy: 0.8329 - loss: 0.3856 - macro_f1_score: 0.8329 - val_accuracy: 0.7684 - val_loss: 0.5380 - val_macro_f1_score: 0.7684\n",
      "Epoch 9/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8542 - loss: 0.3444 - macro_f1_score: 0.8542 \n",
      "Epoch 9: macro_f1_score improved from 0.83054 to 0.84639, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 218ms/step - accuracy: 0.8542 - loss: 0.3445 - macro_f1_score: 0.8542 - val_accuracy: 0.7588 - val_loss: 0.5639 - val_macro_f1_score: 0.7588\n",
      "Epoch 10/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.8584 - loss: 0.3344 - macro_f1_score: 0.8584 \n",
      "Epoch 10: macro_f1_score improved from 0.84639 to 0.86373, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 228ms/step - accuracy: 0.8584 - loss: 0.3344 - macro_f1_score: 0.8584 - val_accuracy: 0.7537 - val_loss: 0.6284 - val_macro_f1_score: 0.7537\n",
      "Epoch 11/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.8782 - loss: 0.3039 - macro_f1_score: 0.8782 \n",
      "Epoch 11: macro_f1_score improved from 0.86373 to 0.87535, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 222ms/step - accuracy: 0.8782 - loss: 0.3040 - macro_f1_score: 0.8782 - val_accuracy: 0.7611 - val_loss: 0.6556 - val_macro_f1_score: 0.7611\n",
      "Epoch 12/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.8803 - loss: 0.2925 - macro_f1_score: 0.8803 \n",
      "Epoch 12: macro_f1_score improved from 0.87535 to 0.88143, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 225ms/step - accuracy: 0.8803 - loss: 0.2926 - macro_f1_score: 0.8803 - val_accuracy: 0.7581 - val_loss: 0.5909 - val_macro_f1_score: 0.7581\n",
      "Epoch 13/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8978 - loss: 0.2702 - macro_f1_score: 0.8978 \n",
      "Epoch 13: macro_f1_score improved from 0.88143 to 0.89194, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 236ms/step - accuracy: 0.8978 - loss: 0.2703 - macro_f1_score: 0.8978 - val_accuracy: 0.7434 - val_loss: 0.6250 - val_macro_f1_score: 0.7434\n",
      "Epoch 14/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.8971 - loss: 0.2634 - macro_f1_score: 0.8971 \n",
      "Epoch 14: macro_f1_score improved from 0.89194 to 0.89434, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 232ms/step - accuracy: 0.8971 - loss: 0.2635 - macro_f1_score: 0.8971 - val_accuracy: 0.7493 - val_loss: 0.7570 - val_macro_f1_score: 0.7493\n",
      "Epoch 15/15\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.9097 - loss: 0.2437 - macro_f1_score: 0.9097 \n",
      "Epoch 15: macro_f1_score improved from 0.89434 to 0.90448, saving model to models_ta_task1_m2\\best_model_ta_task1_m2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m170/170\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 228ms/step - accuracy: 0.9097 - loss: 0.2437 - macro_f1_score: 0.9097 - val_accuracy: 0.7227 - val_loss: 0.7934 - val_macro_f1_score: 0.7227\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step\n",
      "\n",
      "Validation Results:\n",
      "Precision: 0.7517\n",
      "Recall: 0.7227\n",
      "weighted F1 Score: 0.7231\n",
      "macro F1 Score: 0.7227\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_hate       0.84      0.64      0.73       778\n",
      "        hate       0.63      0.84      0.72       578\n",
      "\n",
      "    accuracy                           0.72      1356\n",
      "   macro avg       0.74      0.74      0.72      1356\n",
      "weighted avg       0.75      0.72      0.72      1356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, SpatialDropout1D, Conv1D,\n",
    "    Bidirectional, LSTM, GRU, Dense, Dropout,\n",
    "    GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Configure GPU for optimal performance\n",
    "def configure_gpu():\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Enable memory growth for each GPU\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "            print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "            # Use mixed precision for better performance\n",
    "            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            print('Mixed precision enabled')\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "configure_gpu()\n",
    "\n",
    "# Model Definition - GRU with Attention\n",
    "def create_gru_attention_model(max_len, max_features, embedding_matrix, embed_size=300):\n",
    "    \"\"\"\n",
    "    Creates an enhanced GRU model with hierarchical attention mechanism\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    \n",
    "    # Embedding layer with pretrained weights\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_size,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=max_len,\n",
    "        trainable=True  # Make embeddings trainable for fine-tuning\n",
    "    )(input_layer)\n",
    "    \n",
    "    # Spatial Dropout with higher rate\n",
    "    spatial_dropout = SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # Multiple GRU layers with different window sizes\n",
    "    gru_layer1 = Bidirectional(\n",
    "        GRU(\n",
    "            units=128,\n",
    "            return_sequences=True,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0.2,\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(1e-5)\n",
    "        )\n",
    "    )(spatial_dropout)\n",
    "    \n",
    "    gru_layer2 = Bidirectional(\n",
    "        GRU(\n",
    "            units=64,\n",
    "            return_sequences=True,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0.2\n",
    "        )\n",
    "    )(gru_layer1)\n",
    "    \n",
    "    # Multi-head self-attention (simplified version)\n",
    "    attention_layer = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=8,\n",
    "        key_dim=16\n",
    "    )(gru_layer2, gru_layer2)\n",
    "    \n",
    "    # Skip connection\n",
    "    concat_layer = tf.keras.layers.Concatenate()([gru_layer2, attention_layer])\n",
    "    \n",
    "    # Feature extraction with pooling operations\n",
    "    avg_pool = GlobalAveragePooling1D()(concat_layer)\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(concat_layer)\n",
    "    \n",
    "    # Combine pooled features\n",
    "    concat_pools = tf.keras.layers.Concatenate()([avg_pool, max_pool])\n",
    "    \n",
    "    # Deep MLP layers with batch normalization and more dropout\n",
    "    x = Dense(256, activation='relu')(concat_pools)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output_layer = Dense(2, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Custom macroF1 Score Metric\n",
    "class MacroF1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes = 2, name='macro_f1_score', **kwargs):\n",
    "        super(MacroF1Score, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert probabilities to predicted class indices\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        \n",
    "        # Convert one-hot encoded y_true to class indices if needed\n",
    "        if len(y_true.shape) > 1 and y_true.shape[-1] > 1:\n",
    "            y_true = tf.argmax(y_true, axis=-1)\n",
    "        \n",
    "        # Initialize confusion matrix\n",
    "        conf_matrix = tf.math.confusion_matrix(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            num_classes=self.num_classes,\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        # Calculate TP, FP, FN for each class\n",
    "        diag = tf.linalg.diag_part(conf_matrix)\n",
    "        row_sum = tf.reduce_sum(conf_matrix, axis=1)\n",
    "        col_sum = tf.reduce_sum(conf_matrix, axis=0)\n",
    "        \n",
    "        tp = diag\n",
    "        fp = col_sum - diag\n",
    "        fn = row_sum - diag\n",
    "        \n",
    "        # Update the state variables\n",
    "        self.tp.assign_add(tf.reduce_sum(tp))\n",
    "        self.fp.assign_add(tf.reduce_sum(fp))\n",
    "        self.fn.assign_add(tf.reduce_sum(fn))\n",
    "        self.count.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        # Calculate precision and recall\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "        \n",
    "        # Return macro F1 (average of per-class F1 scores)\n",
    "        return f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.tp.assign(0.)\n",
    "        self.fp.assign(0.)\n",
    "        self.fn.assign(0.)\n",
    "        self.count.assign(0.)\n",
    "            \n",
    "# Model Training\n",
    "def train_and_validate_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=15, model_dir='models_ta_task1_m2'):\n",
    "    \"\"\"\n",
    "    Trains the GRU-Attention model with early stopping and model checkpointing\n",
    "    Returns the best model and training history\n",
    "    \"\"\"\n",
    "    # Create directory for saving models if it doesn't exist\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='macro_f1_score',\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join(model_dir, 'best_model_ta_task1_m2.h5'),  # Save entire model\n",
    "        monitor='macro_f1_score',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Compile model with Adam optimizer (as per paper)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', MacroF1Score(num_classes=2)]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Load the best model found during training\n",
    "    best_model = load_model(os.path.join(model_dir, 'best_model_ta_task1_m2.h5'), \n",
    "                          custom_objects={'MacroF1Score': MacroF1Score})\n",
    "    \n",
    "    return history, best_model\n",
    "\n",
    "# Plot Training History\n",
    "def plot_training_history(history, plot_dir='plots_nlp_project_ta_task1_m2'):\n",
    "    \"\"\"\n",
    "    Plots training history (accuracy and loss curves)\n",
    "    Saves plots to specified directory\n",
    "    \"\"\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, 'training_history_ta_task1_m2.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Validation Evaluation\n",
    "def evaluate_validation(model, X_val, y_val, plot_dir='plots_nlp_project_ta_task1_m2'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on validation data and saves metrics and plots\n",
    "    \"\"\"\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict(X_val, batch_size=32)\n",
    "    \n",
    "    # Convert to class labels\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_true, y_pred, target_names=['not_hate', 'hate'])\n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Not Hate', 'Hate'],\n",
    "                yticklabels=['Not Hate', 'Hate'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Validation)')\n",
    "    plt.savefig(os.path.join(plot_dir, 'confusion_matrix_val_ta_task1_m2.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score_weighted': weighted_f1,\n",
    "        'f1_score_macro': macro_f1,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "# Main Execution for Training and Validation\n",
    "if __name__ == \"__main__\":\n",
    "    # Split into train (80%) and validation (20%)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    # Create model - using GRU with Attention instead of CNN-BiLSTM\n",
    "    embed_size = embedding_matrix.shape[1]\n",
    "    model = create_gru_attention_model(max_len, max_features, embedding_matrix, embed_size)\n",
    "    \n",
    "    # Print model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    history, trained_model = train_and_validate_model(\n",
    "        model, X_train, y_train, X_val, y_val,\n",
    "        batch_size=32,\n",
    "        epochs=15  \n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = evaluate_validation(trained_model, X_val, y_val)\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"Precision: {val_results['precision']:.4f}\")\n",
    "    print(f\"Recall: {val_results['recall']:.4f}\")\n",
    "    print(f\"weighted F1 Score: {val_results['f1_score_weighted']:.4f}\")\n",
    "    print(f\"macro F1 Score: {val_results['f1_score_macro']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(val_results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d84b451f-9ae6-4d97-bad1-91c2abe066ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ta_a1</th>\n",
       "      <th>ta_a2</th>\n",
       "      <th>ta_a3</th>\n",
       "      <th>ta_a4</th>\n",
       "      <th>ta_a5</th>\n",
       "      <th>ta_a6</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ро╡рпИро░роорпБродрпНродрпБ роТро░рпБ роХро╛роо рооро┐ро░рпБроХроорпН роОройрпНрокродрпБ роЪро┐ройро┐рооро╛ родрпБро▒...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#4YrsOfValiantVIVEGAM  #Valimai #AjithKumar   ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#AmbedkarBlueShirtRally  роЗроирпНрод рокрпЛро░ро╛роЯрпНроЯродрпНродрпБроХрпНроХрпБ ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#BREAKING | родро┐ро░рпБроЪрпНроЪро┐ рооро╛ро╡роЯрпНроЯроорпН  роорогрокрпНрокро╛ро▒рпИропрпИ роЕроЯрпБрод...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Bachelor ЁЯШдЁЯШдЁЯШдЁЯШдЁЯШдрокроЯрооро╛роЯро╛ роЗродрпБ роХрпЛродрпНродро╛ &lt;handle repla...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>ЁЯШВЁЯШВЁЯШВ роКроорпНрокрпБ</td>\n",
       "      <td>question_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ЁЯШД родрооро┐ро┤рпН родрпЖро░ро┐роЮрпНроЪро╡ройрпН\"родро╛ройрпН роЙроЩрпНроХрпКроорпНрооро╛ро▓ роХрпБрогрпНроЯро┐ роЕроЯро┐роХ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>ЁЯШЕЁЯШЕЁЯШВЁЯШВ роирпА родро╛ройрпН рокроЩрпН роЕро╡ройрпЛро▓рпБроХрпНроХрпБ роХро░рпЖроХрпНроЯро╛ роЖрой роЖро│рпБ.. ЁЯШО...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>ЁЯШ║тЬП тАФ роЖрооро╛роорпН ро╡рпЗроЪ роЖрооро╛роорпН ро╡рпЗроЪ роЕропрпНроорпН роЪрпНро▓рпАрокро┐ройрпН роЕропрпНроорпН ...</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>є╛Уж :)- Gay  ЁЯЗ▒ЁЯЗ░:)- рокрпКроЯро┐ропройрпН рооро╛ро╕рпНроЯро░рпН ЁЯШВ</td>\n",
       "      <td>question_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1135 rows ├Ч 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   unique_id  ta_a1  \\\n",
       "0        ро╡рпИро░роорпБродрпНродрпБ роТро░рпБ роХро╛роо рооро┐ро░рпБроХроорпН роОройрпНрокродрпБ роЪро┐ройро┐рооро╛ родрпБро▒...  question_1    NaN   \n",
       "1     #4YrsOfValiantVIVEGAM  #Valimai #AjithKumar   ...  question_1    0.0   \n",
       "2     #AmbedkarBlueShirtRally  роЗроирпНрод рокрпЛро░ро╛роЯрпНроЯродрпНродрпБроХрпНроХрпБ ...  question_1    0.0   \n",
       "3     #BREAKING | родро┐ро░рпБроЪрпНроЪро┐ рооро╛ро╡роЯрпНроЯроорпН  роорогрокрпНрокро╛ро▒рпИропрпИ роЕроЯрпБрод...  question_1    0.0   \n",
       "4     #Bachelor ЁЯШдЁЯШдЁЯШдЁЯШдЁЯШдрокроЯрооро╛роЯро╛ роЗродрпБ роХрпЛродрпНродро╛ <handle repla...  question_1    1.0   \n",
       "...                                                 ...         ...    ...   \n",
       "1130                                          ЁЯШВЁЯШВЁЯШВ роКроорпНрокрпБ  question_1    1.0   \n",
       "1131  ЁЯШД родрооро┐ро┤рпН родрпЖро░ро┐роЮрпНроЪро╡ройрпН\"родро╛ройрпН роЙроЩрпНроХрпКроорпНрооро╛ро▓ роХрпБрогрпНроЯро┐ роЕроЯро┐роХ...  question_1    1.0   \n",
       "1132  ЁЯШЕЁЯШЕЁЯШВЁЯШВ роирпА родро╛ройрпН рокроЩрпН роЕро╡ройрпЛро▓рпБроХрпНроХрпБ роХро░рпЖроХрпНроЯро╛ роЖрой роЖро│рпБ.. ЁЯШО...  question_1    NaN   \n",
       "1133  ЁЯШ║тЬП тАФ роЖрооро╛роорпН ро╡рпЗроЪ роЖрооро╛роорпН ро╡рпЗроЪ роЕропрпНроорпН роЪрпНро▓рпАрокро┐ройрпН роЕропрпНроорпН ...  question_1    NaN   \n",
       "1134                 є╛Уж :)- Gay  ЁЯЗ▒ЁЯЗ░:)- рокрпКроЯро┐ропройрпН рооро╛ро╕рпНроЯро░рпН ЁЯШВ  question_1    NaN   \n",
       "\n",
       "      ta_a2  ta_a3  ta_a4  ta_a5  ta_a6  label  \n",
       "0       NaN    0.0    0.0    NaN    0.0      0  \n",
       "1       NaN    1.0    0.0    NaN    NaN      0  \n",
       "2       0.0    0.0    NaN    NaN    NaN      0  \n",
       "3       NaN    0.0    0.0    0.0    0.0      0  \n",
       "4       0.0    NaN    0.0    NaN    NaN      0  \n",
       "...     ...    ...    ...    ...    ...    ...  \n",
       "1130    1.0    NaN    0.0    NaN    NaN      1  \n",
       "1131    1.0    NaN    NaN    1.0    NaN      1  \n",
       "1132    NaN    1.0    0.0    NaN    1.0      1  \n",
       "1133    0.0    NaN    1.0    1.0    NaN      1  \n",
       "1134    1.0    0.0    1.0    NaN    NaN      1  \n",
       "\n",
       "[1135 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = pd.read_csv('test_ta_l1.csv', engine='python', on_bad_lines='skip')\n",
    "d2\n",
    "d2 = d2.rename(columns={'key' : 'unique_id', 'sentence' : 'text'})\n",
    "d2.to_csv('updated_test_ta_l1.csv', index=False)\n",
    "# d2\n",
    "# Convert annotator columns to numeric without replacing NaNs\n",
    "d2[['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']] = d2[\n",
    "    ['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']\n",
    "].apply(pd.to_numeric, errors='coerce')  # NaNs are retained\n",
    "\n",
    "# Compute 'label' based on majority voting while ignoring NaNs\n",
    "d2['label'] = (\n",
    "    d2[['ta_a1', 'ta_a2', 'ta_a3', 'ta_a4', 'ta_a5', 'ta_a6']].mean(axis=1, skipna=True) >= 0.5\n",
    ").astype(int)\n",
    "\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8003a9dd-c81c-4e11-950c-c8897b9ab0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.loc[:, 'binary_label'] = d2['label'].apply(determine_binary_label)\n",
    "\n",
    "# # Reorder columns\n",
    "d2 = d2[['unique_id', 'text', 'binary_label', 'label']]\n",
    "\n",
    "d2.to_csv('updated_test_hi_l1.csv', index=False)\n",
    "\n",
    "d2.loc[:, 'text'] = d2['text'].apply(lambda x: normalize_text(x))\n",
    "processed_list = []\n",
    "for j in d2['text']:\n",
    "    process = j.replace('...','')\n",
    "    processed_list.append(process)\n",
    "\n",
    "df_processed = pd.DataFrame(processed_list)\n",
    "df_processed.columns = ['text']\n",
    "df_processed.head(n=5)\n",
    "\n",
    "X = list(df_processed['text'])\n",
    "y = d2[['label']].values\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Padding\n",
    "X = pad_sequences(X, padding='post', maxlen=max_len)\n",
    "\n",
    "y = label_encoder.fit_transform(y.ravel())\n",
    "\n",
    "y = to_categorical(y, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e2b9a74-01ff-4070-b1e2-851233fc4d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32mтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБтФБ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step\n",
      "\\Test Results:\n",
      "Precision: 0.7743\n",
      "Recall: 0.7639\n",
      "weighted F1 Score: 0.7631\n",
      "macro F1 Score: 0.7635\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_hate       0.83      0.69      0.75       596\n",
      "        hate       0.71      0.84      0.77       539\n",
      "\n",
      "    accuracy                           0.76      1135\n",
      "   macro avg       0.77      0.77      0.76      1135\n",
      "weighted avg       0.77      0.76      0.76      1135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results = evaluate_validation(trained_model, X, y)\n",
    "\n",
    "print(r\"\\Test Results:\")\n",
    "print(f\"Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"Recall: {test_results['recall']:.4f}\")\n",
    "print(f\"weighted F1 Score: {test_results['f1_score_weighted']:.4f}\")\n",
    "print(f\"macro F1 Score: {test_results['f1_score_macro']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(test_results['classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed72587-d1b1-4828-88f2-9fc5d804547a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
